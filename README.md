# ğŸ§  Personal Offline AI Assistant

A **local, offline, privacy-first AI assistant** built using **Ollama + Mistral + Python**.

This assistant can:
- read your personal documents (PDFs, notes),
- answer questions using them via **RAG (Retrieval-Augmented Generation)**,
- maintain **long-term memory with user consent**, and
- help with **daily study planning**,

â€”all **without using the internet or cloud APIs**.

---

## âœ¨ Key Features

- ğŸ”’ **Fully Offline & Private**  
  No cloud APIs, no data leaves your machine.

- ğŸ“š **Document-Aware Q&A (RAG)**  
  Ask questions directly from your PDFs and notes.

- ğŸ§  **Persistent Memory (Opt-in)**  
  The assistant remembers goals only after your confirmation.

- ğŸ“… **Daily Planner Mode**  
  Generates realistic study plans based on your focus areas.

- ğŸ–¥ï¸ **Desktop UI (Tkinter)**  
  Lightweight, responsive desktop interface.

- âš¡ **CPU-Friendly**  
  Designed to run on low-resource systems (no GPU required).

---

## ğŸ—ï¸ Architecture Overview

- **Ollama + Mistral** â†’ Local LLM inference  
- **Python** â†’ Core orchestration & logic  
- **Keyword-based RAG** â†’ Lightweight retrieval (CPU-friendly)  
- **Tkinter** â†’ Desktop UI  
- **JSON Memory** â†’ Explicit, user-controlled persistence  

---

## ğŸ“‚ Project Structure

personal_ai_assistant/
â”œâ”€â”€ assistant.py # Core logic (RAG, memory, planner)
â”œâ”€â”€ ui.py # Desktop UI
â”œâ”€â”€ memory.json # Persistent memory (ignored by Git)
â”œâ”€â”€ ai_docs/ # User documents (PDF/TXT)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


> âš ï¸ `memory.json` and `ai_docs/` are intentionally ignored in Git for privacy.

---

## ğŸš€ Step-by-Step: How to Run the Project

### âœ… Prerequisites

Make sure you have:
- **Python 3.10+**
- **Git**
- **Ollama installed**

ğŸ‘‰ Install Ollama from: https://ollama.com

---

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/personal-ai-assistant.git
cd personal-ai-assistant

2ï¸âƒ£ Install Python Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Pull the LLM Model (One-Time Setup)
ollama pull mistral

4ï¸âƒ£ Add Your Documents
Place your files inside the ai_docs/ folder:

.txt

.md

.pdf
Example
ai_docs/
â”œâ”€â”€ computer_networks_notes.pdf
â”œâ”€â”€ os_summary.txt

5ï¸âƒ£ Run the Desktop UI
python ui.py

ğŸ§ª Example Commands to Try

plan my day

Explain OSI model

What is TCP/IP from my notes?

Remember that I am studying Computer Networks

What am I currently focusing on?

ğŸ§  Learning Outcomes

By building this project, I learned how to:

Design and implement a full RAG pipeline from scratch

Build safe, explicit memory systems for AI assistants

Optimize LLM workflows for CPU-only environments

Create a responsive threaded UI in Python

Think in terms of LLM system design, not just prompts

ğŸ“Œ Future Improvements

Semantic embeddings for smarter retrieval

OCR support for scanned PDFs

Web or mobile UI

Model switching (Mistral, LLaMA, etc.)

ğŸ‘¤ Author

Abhay
Computer Engineering Student
Interested in AI Systems, Data Engineering, and LLM Architectures

